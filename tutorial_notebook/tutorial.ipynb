{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import sys\n",
    "sys.path.append(\"../subjective-fits/\")\n",
    "import seaborn as sns\n",
    "figsize(8,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mpl.rcParams['xtick.labelsize'] = 22\n",
    "mpl.rcParams['ytick.labelsize'] = 22\n",
    "plt.rc('axes', labelsize=22)\n",
    "plt.rc('legend', fontsize=22)\n",
    "mpl.rcParams['ps.useafm'] = True\n",
    "mpl.rcParams['pdf.use14corefonts'] = True\n",
    "mpl.rcParams['text.usetex'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing approaches to subjective probability and statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We illustrate various approaches to statistics based on subjective probability. Our test case is the estimation of the mean of a one-dimensional Gaussian. We will demonstrate each approach to subjective probability using one point estimate and one \"uncertainty\" interval. We will also comment on the mathematical derivation as well as the interpretation of these two outputs for each approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The setting is $x_1,\\dots,x_N\\sim\\mathcal{N}(\\theta,\\sigma^2)$, with $\\sigma^2$ known. The statistician's goal is to infer $\\theta$, and state his uncertainty about his estimate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateData(N, mu, sigma2, tag=\"well-specified\"):\n",
    "    if tag==\"well-specified\":\n",
    "        return mu+np.sqrt(sigma2)*npr.randn(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#npr.seed(1)\n",
    "thetaTrue = 1 # \"true\" value of the mean\n",
    "sigma2True = 1\n",
    "alpha = .05\n",
    "gamma = 0.5 # importance of the length of the interval vs. the interval containing the true value\n",
    "N = 10\n",
    "x = generateData(N, thetaTrue, sigma2True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is denoted by $\\mathcal{D}= \\left\\lbrace x_1, ..., x_N \\right\\rbrace$. The corresonding likelihood function is \n",
    "$$ \\mathcal{L} \\left( \\theta; \\mathcal{D} \\right)  = \\prod_{i=1}^N \\frac{1}{\\sigma \\sqrt{2\\pi}}\\exp \\left( - \\frac{\\left( \\theta - x_i \\right)^2}{2 \\sigma^2} \\right).$$\n",
    "\n",
    "The maximum likelihood estimate (MLE) of $\\theta$ is the sample mean $\\bar{x}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intervals = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjugate Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Bayesian paradigm\n",
    "The Bayesian approach is based on the expected utility principle. \n",
    "* First, define a cost function $L(\\theta,a)$ that measures how much you suffer from picking action $a$ when the state of the world --here, the variable to infer-- is $\\mu$. Actions should be functions from the set of states of the world to a space of \"outcomes\". For our application, an action should consist in picking an estimate $\\hat{\\theta}$ and a small enough interval $I$, and the outcomes that matter to know if we've suceeded are $a(\\theta) = (\\theta-\\hat{\\theta}, \\vert I\\vert, 1_{\\theta\\in I})$. So we need to define $L(\\theta,a) = L(\\theta,\\hat{\\theta},I)$. \n",
    "* Second, simply choose a pdf $p(\\theta)$ over states of the world, your prior, and choose the action $a$ that minimizes the posterior expected loss\n",
    "$$\n",
    "\\mathbb{E}_\\pi L(\\theta, a) = \\int L(\\theta, a) \\pi(\\theta)d\\theta,\n",
    "$$\n",
    "where we have denoted by $\\pi(\\theta)$ the probability distribution function (pdf) proportional to $p(x\\vert\\theta)p(\\theta)$. By Bayes' theorem, this is the conditional pdf of $\\theta$ given data $x$, also called the posterior distribution. \n",
    "\n",
    "### Choosing a loss function\n",
    "For the estimate $\\hat{\\theta}$, we follow here the long tradition of squared losses and we decide to suffer $(\\theta-\\hat{\\theta})^2$ if we output $\\hat{\\theta}$ while the actual mean of the Gaussian is $\\theta$. For the interval, we want to penalize intervals that do not contain the actual $\\theta$, while also penalizing intervals that are too wide, to avoid vacuous statements like $I=\\mathbb{R}$. This leads us to\n",
    "\n",
    "$$ L \\left (\\theta, \\hat{\\theta}, I \\right) = (\\theta-\\hat{\\theta})^2 + \\gamma \\vert I\\vert + 1_{\\theta\\notin I}. $$\n",
    "\n",
    "The parameter $\\gamma>0$ needs to be chosen by the user, and is interpreted as how much the user favors small intervals over intervals that contain the actual value. There is no need for an additional tradeoff parameter in front of the first term of the right-hand side, since \n",
    "$$\n",
    "\\min_{\\hat{\\theta}, I} \\mathbb{E}_\\pi L(\\theta, \\hat{\\theta}, I) = \\min_{\\hat{\\theta}}\\mathbb{E}_\\pi (\\theta-\\hat{\\theta})^2 + \\min_I \\left[\\gamma \\vert I \\vert + \\int 1_{\\theta\\notin I} \\pi(\\theta) d\\theta \\right]. \n",
    "$$\n",
    "Actually this global optimization problem breaks into two simpler ones (wrt to $\\theta$ and wrt $I$).\n",
    "\n",
    "By a property of the mean, the Bayesian estimate $\\hat{\\theta}$ for our choice of loss is thus the mean of the posterior distribution $\\pi$. The Bayesian estimate of $I$ is not obvious at this stage.\n",
    "\n",
    "### Picking a prior\n",
    "Now, if our prior $p(\\theta)$ is a Gaussian $\\mathcal{N}(\\mu_\\text{prior}, \\sigma^2_\\text{prior})$, and our likelihood is also Gaussian $\\mathcal{N}(\\theta,\\sigma^2)$, you can check that the posterior $\\pi$ is \n",
    "\\begin{equation}\n",
    "\\mathcal{N}\\left( \\frac{\\frac{\\mu_\\text{prior}}{\\sigma^2_\\text{prior}}+\\frac{\\sum_{i=1}^N x_i}{\\sigma^2}}{\\frac{1}{\\sigma^2_\\text{prior}}+\\frac{N}{\\sigma^2}} ,  \\frac{1}{\\sigma^2_\\text{prior}}+\\frac{N}{\\sigma^2} \\right) .\n",
    "\\label{e:posterior}\n",
    "\\end{equation}\n",
    "This setting where the posterior has the same functional form (here Gaussian) as the prior is called \"conjugate\", hence the title of this section. Note that we chose a conjugate prior as a mathematical convenience and because it allows easy interpretation, but being Bayesian does not require it. Note how the mean of the posterior is a convex combination of the prior mean and the average of the data points. `ConjugateBayes.estimate()` simply returns this convex combination. \n",
    "\n",
    "Because the posterior is Gaussian, an interval of given width will always contain more posterior mass if it is centered around the posterior mean. Hence, we can limit our search for the best $I$ to intervals $I_\\alpha$ centered around the mean, where $\\alpha$ indicates that the posterior puts mass $1-\\alpha$ on this interval. Computing the endpoints of $I_\\alpha$ simply involves calling the `erf` function, and that is what `ConjugateBayes.interval(1-alpha)` does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ConjugateBayes as cb\n",
    "cb = cb.ConjugateBayes(data=x, sigma2Lhd=sigma2True**2, muPrior=10, sigma2Prior=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each approach should be implemented in one class, in a separate python file. Each approach should have the following two methods:\n",
    "print(cb.estimate()) # yields a point estimate, here the posterior mean\n",
    "print(cb.interval(1-alpha)) # yields an uncertainty quantification, here a credible interval of posterior mass 1-alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now recall that among centered intervals, I want to pick the $I_\\alpha$ with the lowest integrated cost \n",
    "$$\\gamma \\vert I_\\alpha\\vert +  \\int \\left(1_{\\theta\\notin I_\\alpha}\\right) \\pi(\\theta)d\\theta = \\gamma \\vert I_\\alpha\\vert + \\alpha$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(0.01,.99, 100)\n",
    "costs_cb = []\n",
    "for alpha_loc  in alphas:\n",
    "    # Compute cost for various alphas\n",
    "    lo, hi = cb.interval(1-alpha_loc)\n",
    "    costs_cb.append( gamma*(hi-lo) + alpha_loc )\n",
    "\n",
    "ind = np.argmin(costs_cb) # Find the alpha that minimizes the cost\n",
    "alphaStar = alphas[ind]\n",
    "intervals[\"conjugate Bayes\"] = cb.interval(1-alphaStar)\n",
    "print(\"The cost is minimized for alpha=\", alphaStar)\n",
    "print(\"The interval is then\", intervals[\"conjugate Bayes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can visualize the cost as a function of alpha\n",
    "plt.plot(alphas, costs_cb, color='b') \n",
    "\n",
    "# adjust the plotting window and show minimizer\n",
    "m = np.min(costs_cb) \n",
    "M = np.max(costs_cb)\n",
    "delta = M-m\n",
    "yMin = m-.5*delta\n",
    "yMax = M+.5*delta\n",
    "plt.ylim([yMin,yMax])\n",
    "plt.vlines(alphaStar,yMin,yMax,linestyle='--',color='blue')\n",
    "\n",
    "plt.xlabel(r\"$\\alpha$\")\n",
    "plt.ylabel(\"cost\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bayes action is to report the credible interval with $\\alpha$ set to the minizer of this curve! We can also visualize this interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, res in enumerate(intervals.items()):\n",
    "    method, interval = res\n",
    "    plt.plot([k, k], [interval[0], interval[1]], label=method, linewidth=6)\n",
    "    plt.grid()\n",
    "    plt.ylabel(r\"$\\theta$\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finitely additive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected utility principle, along with the rule that says you should update your beliefs by conditioning on observed events, can be axiomatized. One of the most significant work in this direction is known as Savage's axioms, which is usually what statisticians refer to when they claim  that \"being Bayesian is being a coherent rational agent\". However, Savage's axioms actually only warrant using finitely additive probability measures, and these measures have to be defined for all subsets of the set of states of the world. This is incompatible with using a Gaussian prior over $\\theta\\in\\mathbb{R}$, as there will be nonmeasurable sets for this Gaussian. TBC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood based Belief Function\n",
    "\n",
    "### Definitions\n",
    "\n",
    "In the belief function framework, as well as in other ill-known probabilities frameworks, we work with a pair of functions interpreted as lower and upper bounds of the odds of $\\theta$ being $\\mu$. The lower bound $bel$ is called **belief function** while the upper bound $pl$ is called **plausibility function**. These functions are set functions, which means that their domain is the set of subsets of $\\Theta = \\mathbb{R}$. For any subset $A\\subset \\Theta$, the two functions are related by\n",
    "\n",
    "$$bel \\left( A \\right) = 1 - pl \\left(A^c\\right).$$\n",
    "\n",
    "There are several ways to derive such function. In this notebook, we present belief functions *Ã  la Dempster* which are induced by a random set. Let $(\\Omega,\\sigma_\\Omega,\\mu)$ denote a  probability space. Define a mapping $\\Gamma$ from $\\Omega$ to the set of subsets of $\\Theta$. Under measurability conditions, $\\Gamma$ is a **random set**. We can define the two following pseudo-inverse for $\\Gamma$:\n",
    "$$ \\Gamma^{-1}_{\\top}\\left(B\\right) = \\left\\lbrace \\omega | \\Gamma\\left(\\omega\\right)\\cap B \\neq \\emptyset \\right\\rbrace,\\forall B\\subseteq \\Theta ,\\\\\n",
    "\\Gamma^{-1}_{\\bot}\\left(B\\right) = \\left\\lbrace \\omega | \\Gamma\\left(\\omega\\right)\\subseteq B \\right\\rbrace,\\forall B\\subseteq \\Theta .$$\n",
    "\n",
    "Then, we have $pl = \\mu \\circ \\Gamma^{-1}_{\\top}$ and $bel = \\mu \\circ \\Gamma^{-1}_{\\bot} $.\n",
    "\n",
    "**Example**:\n",
    "\n",
    "Going back to our inference problem for $\\theta$, we can use the likelihood based belief function. The corresponding plausibility function is defined as \n",
    "$$ pl \\left( \\theta \\right) = \\frac{\\mathcal{L} \\left( \\theta ; \\mathcal{D} \\right)}{\\mathcal{L} \\left( \\bar{x} ; \\mathcal{D} \\right)}, \\forall \\theta \\in \\mathbb{R} \\\\\n",
    "pl \\left( H \\right) = \\underset{\\theta \\in H}{\\sup} pl \\left( \\theta \\right), \\forall H \\subseteq \\mathbb{R}\n",
    "$$\n",
    "\n",
    "This model stems from the probability space $(U,\\sigma_U,\\lambda)$ where $U$ is the unit interval, $\\sigma_U$ the Borel sigma-field on this interval and $\\lambda$ is the uniform probability measure. Now, by mapping each $u \\in U$ to the $\\alpha$-cut of function $\\frac{\\mathcal{L} \\left( \\theta ; \\mathcal{D} \\right)}{\\mathcal{L} \\left( \\bar{x} ; \\mathcal{D} \\right)}$, we span the above plausibility function.\n",
    "\n",
    "**Interpretation**:\n",
    "For any event $H$, we can understand the belief and plausibility values as:\n",
    "* $bel \\left( H\\right)$ : probability to know that $H$ is true,\n",
    "* $pl \\left( H\\right)$ : probability to know that $H^c$ is false,\n",
    "* $pl \\left( H\\right) - bel \\left( H\\right)$ : probability not to know whether $H$ is true.\n",
    "\n",
    "So we see that the probability mass $pl \\left( H\\right) - bel \\left( H\\right)$ is not assigned to any outcome $H$ or $H^c$ in light of the available data.\n",
    "\n",
    "In the specific case of the Likelihood based belief function, we also have random interval interpretation. In this case, we build the belief function by choosing uniformly a confidence level $\\alpha$ and propagate the correponding probability measure to the $\\alpha$-cuts of the likelihood function. $bel\\left(H\\right)$ is then the probability that the random interval is included in $H$ while $pl\\left(H\\right)$ is the probability that the random interval intersects $H$.\n",
    "\n",
    "### Belief functions and decision theory\n",
    "\n",
    "Like the Bayesian paradigm, making decisions with belief functions can also be formalized using expected utility. \n",
    "Yet belief functions are non-additive measures and we cannot integrate a cost against them in the sense of Lebesgue integral. For this purpose, we need to resort a non-additive integral now as Choquet integral. Let alone these technicalities, making decisions using a belief function shares the same philosophy as in the Bayesian case:\n",
    "\n",
    "* First, also pick a loss function. In the sequel, we will go for a different loss function as before but our aim is still the same. We need to pick an estimate of $\\theta$ and a small condidence interval which is believed to contain $\\theta$. We will also penalize incorrect estimations, large intervals and intervals that miss $\\theta$.\n",
    "* Second, update your prior information with your data. The information drawn from the data is embodied by the likelihood based belief function. The prior information is also a belief function. The two functions are combined through an operation called Dempster's rule which we do not detail here. In the case your prior information is a probability distribution, then Dempster's rule yields a posterior distribution which conincides with the Bayesian approach. In the sequel, we choose a genuinely uninformative prior, i.e. a vacuous belief function ($bel = 1_\\Theta$).\n",
    "* Finally, choose the action that minimizes the integrated cost. However, we have two non additive measures against which it can be integrated :\n",
    "  $$ (C)\\int J\\: dbel  \\text{ (Conservative approach)},\\\\\n",
    "  (C)\\int J\\: dpl  \\text{ (Optimistic approach)},$$\n",
    "  \n",
    "  where $(C)\\int$ is the Choquet integral symbol.\n",
    "  \n",
    "We also need to define a notion of \"condidence\" interval for belief functions. Here, we propose to define $I_\\alpha$ as the centered interval on the MLE such that $bel \\left( I_\\alpha \\right) = 1 - \\alpha$ which is understood as the probability that $\\theta \\in I_\\alpha$ is at least $1 - \\alpha$.\n",
    "\n",
    "Just like Bayesians do with Savage's theorem, BF practionners invoke Gilboa's theorem to claim that the BF approach is compliant with rational decision making. As proved by Gilboa, appraising the cost of an action based on expected utility relying on non-additive measures translates into a sound preference relation among actions. However, two important restrictions appear in Gilboa's axiomatization: the utility function must be bounded (we will comply to this requirement in the sequel) and the non-additive measure must have convex range.\n",
    "\n",
    "### Choosing a loss function\n",
    "\n",
    "The non-additivity of belief function does not only prevent us from using many mathematical results but also lead to non-intuitive calculations for people who are familiar with standard probability calculus. In particular, we can use the $0-1$ loss $L_{0-1}$ for the estimation of $\\theta$, while this would be pointless in the probabilistic case as singletons have null Lebesgue measure. In the likelihood belief function case, we have \n",
    "\n",
    "$$ (C)\\int L_{0-1}\\: dbel = 1 - pl \\left( \\hat{\\theta} \\right) ,\\\\\n",
    "  (C)\\int L_{0-1}\\: dpl = 1.$$\n",
    "\n",
    "We see that for the 1st cost we obtain $\\hat{\\theta} = \\bar{x}$, while with the second we cannot draw any conclusion. We thus adopt here the 1st approach for the estimation of $\\theta$, and the method  `BaselineBF.estimate` thus returns the MLE estimate.\n",
    "\n",
    "For the interval estimation problem, we will use the same cost function as before, and we obtain\n",
    "$$ (C)\\int \\vert I\\vert + 1_{\\theta\\notin I} \\: dbel = \\gamma \\vert I_\\alpha \\vert ,\\\\\n",
    "  (C)\\int  \\vert I\\vert + 1_{\\theta\\notin I}\\: dpl = \\gamma \\vert I_\\alpha \\vert + \\alpha .$$\n",
    "  \n",
    "This time, it is the second cost minimization that is instrumental because the 1st one is always minimized for $\\alpha=1$, meaning that $I_\\alpha = \\left\\lbrace \\bar{x} \\right\\rbrace$. So we see that we cannot use the same non-additive measure for both estimation problems. This is not much problematic as these two can be decoupled, yet we obviously cannot achieve the same level of unification as the Bayesian approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import BaselineBF as bf\n",
    "bf = bf.BaselineBF(data=x, sigma2Lhd=sigma2True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bf.estimate()) # yields a point estimate, here the MLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Now, we are still interested in the same interval cost function $J \\left(\\alpha \\right)$ \n",
    "  \n",
    "  The method `BaselineBF.interval` returns the estimated \"confidence\" interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bf.interval(1-alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs_cons = []\n",
    "costs_optm = []\n",
    "for alpha_loc  in alphas:\n",
    "    lo, hi = bf.interval(1-alpha_loc)\n",
    "    costs_cons.append( gamma*(hi-lo))\n",
    "    costs_optm.append( gamma*(hi-lo) + alpha_loc )\n",
    "\n",
    "yMin = 0\n",
    "yMax = np.max(costs_optm)\n",
    "plt.ylim([yMin,yMax])\n",
    "\n",
    "# Conservative approach\n",
    "ind = np.argmin(costs_cons) # Find the alpha that minimizes the cost\n",
    "alphaStar = alphas[ind]\n",
    "plt.vlines(alphaStar,yMin,yMax,linestyle='--',color='red')\n",
    "print(\"The conservative cost is minimized for alpha=\", alphaStar)\n",
    "lo, hi = bf.interval(1-alphaStar)\n",
    "intervals[\"conservative likelihood-based BF\"] = [lo, hi]\n",
    "print(\"The interval is then\", intervals[\"conservative likelihood-based BF\"])\n",
    "\n",
    "# Optimistic approach\n",
    "ind = np.argmin(costs_optm) # Find the alpha that minimizes the cost\n",
    "alphaStar = alphas[ind]\n",
    "plt.vlines(alphaStar,yMin,yMax,linestyle='--',color='green')\n",
    "print(\"The optimistic cost is minimized for alpha=\", alphaStar)\n",
    "lo, hi = bf.interval(1-alphaStar)\n",
    "intervals[\"optimistic likelihood-based BF\"] = [lo, hi]\n",
    "print(\"The interval is then\", intervals[\"optimistic likelihood-based BF\"])\n",
    "\n",
    "# plot the costs\n",
    "plt.plot(alphas, costs_cons, label=\"conservative\", color='r')\n",
    "plt.plot(alphas, costs_optm, label=\"optimistic\", color='g')\n",
    "plt.plot(alphas, costs_cb, label=\"conjugate Bayes\", color='b')\n",
    "\n",
    "# show the minimzers\n",
    "\n",
    "plt.xlabel(r\"$\\alpha$\")\n",
    "plt.ylabel(\"cost\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We focus on the optimistic cost as the conservative does not provide a sufficient level of information. In this experiment, the optimistic cost is minimized for the same value of $\\alpha$ as in the conjugate Bayes case. This may be purely conincidental as other values of $\\gamma$ may not lead to such a result. Obviously, when $\\gamma$ is small, both costs become closer. \n",
    "\n",
    "We also see that the optimistic cost curve is not convex while the conjugate Bayes curve seems to be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Comparing intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, res in enumerate(intervals.items()):\n",
    "    method, interval = res\n",
    "    plt.plot([k, k], [interval[0], interval[1]], label=method, linewidth=6)\n",
    "    plt.grid()\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
